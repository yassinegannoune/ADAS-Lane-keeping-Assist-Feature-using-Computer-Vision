{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7bb6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "from docopt import docopt\n",
    "from IPython.display import HTML, Video\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6190a02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usage des classes est primordoale dans la realisation de ce projet\n",
    "#on peut facilement acceder a n'importe quel methode et standariser usage pour des futur application\n",
    "class CameraCalibration():\n",
    "    def __init__(self, image_dir, nx, ny, debug=False):\n",
    "        #initialisation de la classe de calibration pour permmettre assigner les valeurs du Object propertis\n",
    "        #nx:le nbr de carreaux qui a une intersection en horizantal dans notre chessboard\n",
    "        #ny:le nbr de carreaux qui a une intersection en vertical dans notre chessboard.\n",
    "        #image_dir:correspond au chemin des images prises par la camera en utilisant glob function\n",
    "        fnames = glob.glob(\"{}/*\".format(image_dir))\n",
    "        objpoints = []\n",
    "        imgpoints = []\n",
    "        objp = np.zeros((nx*ny, 3), np.float32)\n",
    "        objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1, 2)\n",
    "        \n",
    "        for f in fnames:\n",
    "            img = mpimg.imread(f)\n",
    "            #une bonne pratique de passer en RGB-->GRAY pour reduire Computation time puisque on s'interesse seulment sur \n",
    "            #la detection des lignes.\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "            #la fonction essential pour la calibration de l'image:\n",
    "            #------->img:frame from while loop  that reads our record \n",
    "            #------->(nx,ny):pattern size:C'est un tuple spécifiant la taille de l'échiquier en nombre de coins internes. \n",
    "            ret, corners = cv2.findChessboardCorners(img, (nx, ny))\n",
    "            if ret:\n",
    "                imgpoints.append(corners)\n",
    "                objpoints.append(objp)\n",
    "\n",
    "        shape = (img.shape[1], img.shape[0])\n",
    "        #mtx and dist correspond :\n",
    "        #--------->mtx:matrice de la caméra| array:3X3\n",
    "        #--------->dist:coefficient de distorsion\n",
    "        ret, self.mtx, self.dist, _, _ = cv2.calibrateCamera(objpoints, imgpoints, shape, None, None)\n",
    "        #enregister les parametres dans un file .p pour des futurs utilisations pour optimiser le temps de calibrations des images\n",
    "        if os.path.exists('camera_parameteres.p'):\n",
    "            with open('camera_parameteres.p', mode='rb') as f:\n",
    "                #si le fichier existe fait ceci:\n",
    "                data = pickle.load(f)\n",
    "                self.mtx, self.dist = data['mtx'], data['dist']\n",
    "                print('Success du sauvegarde des parameters dans le chemin desiree')\n",
    "        else:\n",
    "            with open('camera_parameteres.p', mode='wb') as f:\n",
    "                pickle.dump({'mtx': self.mtx, 'dist': self.dist}, f)\n",
    "         #---------------------------------------------------------------------------------------------------------------   \n",
    "        if not ret:\n",
    "            raise Exception(\"Impossible de calibrer Camera\")\n",
    "\n",
    "    def undistort(self, img):\n",
    "        #tous les images a traiter doivent etre appliquer a une distortion pour des differentes raisons.\n",
    "        #L'application de la correction de distorsion sur une image permet de compenser ces déformations\n",
    "        #et de rétablir une représentation plus précise des objets dans l'image. \n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        return cv2.undistort(img, self.mtx, self.dist, None, self.mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ec8aceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cette classe a pour essentiel d'appliquer thrsholding sur image pour changer espace de couleur de image\n",
    "#pour objectif de se concentrer dans le traitement seulmengt sur la zone des lignes de la route\n",
    "class Thresholding:\n",
    "    def __init__(self):\n",
    "        #nothing to do-----------------------------\n",
    "        pass\n",
    "\n",
    "    def forward(self, img):\n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "        lower = np.array([ 0 ,160,0])\n",
    "        upper = np.array([151, 242, 255])\n",
    "        mask = cv2.inRange(hls, lower, upper)\n",
    "        img2=mask\n",
    "        return img2\n",
    "    def adaptif_thresholding_ots(self,img):\n",
    "        #application de otsu thresholding qui permet dans la plus part des cas d'une bonne detection des roues\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        return binary\n",
    "    def combination_thr(self,img):\n",
    "        #appliquation du gradient thresholding qui donne meiller resultats------plus part des cas seul\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        gradient_mag = np.sqrt(sobelx ** 2 + sobely ** 2)\n",
    "        gradient_mag = np.uint8(255 * gradient_mag / np.max(gradient_mag))\n",
    "        _, binary = cv2.threshold(gradient_mag, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        mask_sobel=binary\n",
    "        #premiere model de couleur:HSV(Hue,Saturation,Value)\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        lower_white = np.array([0,0,168])  \n",
    "        upper_white = np.array([172,111,255])\n",
    "        mask_hsv = cv2.inRange(hsv, lower_white, upper_white)\n",
    "        #application des combination\n",
    "        combination1=mask_hsv|mask_sobel\n",
    "        combination2=mask_hsv|adaptif_thresholding_ots(img)\n",
    "        combination3=mask_hsv & mask_sobel\n",
    "        combination4=mask_hsv & adaptif_thresholding_ots(img)\n",
    "        combination_score = cv2.countNonZero(combined_image)\n",
    "        binary_images = [combination1, combination2, combination3,combination4]\n",
    "        num_images = len(binary_images)\n",
    "        #choisir le meilleur qui comprends les meilleur detection\n",
    "        for i in range(1, 2 ** num_images):\n",
    "            combination = format(i, f'0{num_images}b')\n",
    "            combined_image = np.zeros_like(img)\n",
    "            for j, binary_image in enumerate(binary_images):\n",
    "                if combination[j] == '1':\n",
    "                    combined_image = cv2.bitwise_or(combined_image, binary_image)\n",
    "            combination_score = cv2.countNonZero(combined_image)\n",
    "            if combination_score > best_combination_score:\n",
    "                best_combination = combined_image\n",
    "                best_combination_score = combination_score\n",
    "                \n",
    "        return best_combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d65c79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# la perspective est une methode qui transforme les points d'une image \n",
    "#en d'autres points correspondants dans une nouvelle vue.pour obtenir une vue plus rectiligne \n",
    "class PerspectiveTransformation:\n",
    "    def __init__(self):\n",
    "        #initialisation des parametres de getprespective qui comprend:\n",
    "        #---->src:Ces points représentent les coins ou les repères de la région d'intérêt dans l'image source \n",
    "        #---->dst: Ces points représentent les positions auxquelles les points src correspondants après la transformation.\n",
    "        #---->flags=specification du type de l'interpolation\n",
    "        self.src = np.float32([(397, 228),(101, 361),(1267, 336),(943, 218)])\n",
    "        self.dst = np.float32([(100, 0),\n",
    "                               (100, 720),\n",
    "                               (1100, 720),\n",
    "                               (1100, 0)])\n",
    "        self.M = cv2.getPerspectiveTransform(self.src, self.dst)\n",
    "        self.M_inv = cv2.getPerspectiveTransform(self.dst, self.src)\n",
    "\n",
    "    def forward(self, img, img_size=(1280, 720), flags=cv2.INTER_LINEAR):\n",
    "        return cv2.warpPerspective(img, self.M, img_size, flags=flags)\n",
    "    #Passage du top_View a image original\n",
    "    def backward(self, img, img_size=(1280, 720), flags=cv2.INTER_LINEAR):\n",
    "        return cv2.warpPerspective(img, self.M_inv, img_size, flags=flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d24e9d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist(img):\n",
    "    #on concentre etude sur la partie moitie de histogramm puisque c'est ou il se trouve les voies\n",
    "    #tous en eiminant les bruits et les informations non necessaires \n",
    "    bottom_half = img[img.shape[0]//2:,:]\n",
    "    return np.sum(bottom_half, axis=0)\n",
    "\n",
    "class detect_lines:\n",
    "    def __init__(self):\n",
    "        #initialisation des coefficient des parametres des lignes d'ordre 2\n",
    "         #Y=Ax^2 +Bx+C-------->second order equation\n",
    "        self.left_coeff = None\n",
    "        self.right_coeff = None\n",
    "        self.nonzero = None\n",
    "        self.zeros_posx = None\n",
    "        self.zeros_posy = None\n",
    "        self.drirection_val = []\n",
    "        #partie concernee au niveau de manipulation output_video\n",
    "        self.virage_left = mpimg.imread('left_turn.png')\n",
    "        self.virage_right = mpimg.imread('right_turn.png')\n",
    "        self.ligne_droite = mpimg.imread('straight.png')\n",
    "        self.keep_warn = mpimg.imread('seat_belt.png')\n",
    "        self.virage_left = cv2.normalize(src=self.virage_left, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "        self.virage_right = cv2.normalize(src=self.virage_right, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "        self.ligne_droite = cv2.normalize(src=self.ligne_droite, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "        self.keep_warn = cv2.normalize(src=self.keep_warn, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "        #sliding_window_technique---------------------\n",
    "        self.nwindows = 9         #9 windows or 12 for good\n",
    "        self.margin = 100\n",
    "        self.minpix = 50\n",
    "\n",
    "    def forward(self, img):\n",
    "        self.extract_features(img)\n",
    "        return self.apply_poly(img)\n",
    "\n",
    "    def coordinates_pos_windows(self, center, margin, height):\n",
    "        topleft = (center[0]-margin, center[1]-height//2)\n",
    "        bottomright = (center[0]+margin, center[1]+height//2)\n",
    "        #2 conditions pour savoir si les pixels desirees de la lignes se situe a interieur de window\n",
    "        condx = (topleft[0] <= self.zeros_posx) & (self.zeros_posx <= bottomright[0])\n",
    "        condy = (topleft[1] <= self.zeros_posy) & (self.zeros_posy <= bottomright[1])\n",
    "        return self.zeros_posx[condx&condy], self.zeros_posy[condx&condy]\n",
    "\n",
    "    def extract_features(self, img):\n",
    "        self.img = img\n",
    "        self.window_height = np.int(img.shape[0]//self.nwindows)\n",
    "        self.nonzero = img.nonzero()\n",
    "        self.zeros_posx = np.array(self.nonzero[1])\n",
    "        self.zeros_posy = np.array(self.nonzero[0])\n",
    "\n",
    "    def find_lane_pixels(self, img):\n",
    "        #pour des verification en phase de test en utilise assert qui correspond a un debugging tool\n",
    "        assert(len(img.shape) == 2)\n",
    "        #ensembe de frames de la video a manipuler pour notre final output\n",
    "        out_img = np.dstack((img, img, img))\n",
    "        #detection les positions des lignes droites et gauches en suivant les piques affiche dans histogramme\n",
    "        histogram = hist(img)\n",
    "        midpoint = histogram.shape[0]//2\n",
    "        leftx_base = np.argmax(histogram[:midpoint])\n",
    "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "        # positions relatives des lignes droites et gauches pour chaque fenetre\n",
    "        leftx_current = leftx_base\n",
    "        rightx_current = rightx_base\n",
    "        y_current = img.shape[0] + self.window_height//2\n",
    "\n",
    "        \n",
    "        leftx, lefty, rightx, righty = [], [], [], []\n",
    "\n",
    "        # iterarions toutes les fenetres\n",
    "        for _ in range(self.nwindows):\n",
    "            y_current -= self.window_height\n",
    "            center_left = (leftx_current, y_current)\n",
    "            center_right = (rightx_current, y_current)\n",
    "\n",
    "            leftx_vrai_pos, lefty_vrai_pos = self.coordinates_pos_windows(center_left, self.margin, self.window_height)\n",
    "            rightx_vrai_pos, righty_vrai_pos = self.coordinates_pos_windows(center_right, self.margin, self.window_height)\n",
    "\n",
    "            # Append these indices to the lists\n",
    "            leftx.extend(leftx_vrai_pos)\n",
    "            lefty.extend(lefty_vrai_pos)\n",
    "            rightx.extend(rightx_vrai_pos)\n",
    "            righty.extend(righty_vrai_pos)\n",
    "\n",
    "            if len(leftx_vrai_pos) > self.minpix:\n",
    "                leftx_current = np.int32(np.mean(leftx_vrai_pos))\n",
    "            if len(rightx_vrai_pos) > self.minpix:\n",
    "                rightx_current = np.int32(np.mean(rightx_vrai_pos))\n",
    "\n",
    "        return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "    def apply_poly(self, img):\n",
    "        leftx, lefty, rightx, righty, out_img = self.find_lane_pixels(img)\n",
    "        #apres 1500 acquisition des points rechercher les coefficients des 2 droites(A,B,C)\n",
    "        if len(lefty) > 1500:\n",
    "            self.left_coeff = np.polyfit(lefty, leftx, 2)\n",
    "        if len(righty) > 1500:\n",
    "            self.right_coeff = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "        maxy = img.shape[0] - 1\n",
    "        miny = img.shape[0] // 3\n",
    "        if len(lefty):\n",
    "            maxy = max(maxy, np.max(lefty))\n",
    "            miny = min(miny, np.min(lefty))\n",
    "\n",
    "        if len(righty):\n",
    "            maxy = max(maxy, np.max(righty))\n",
    "            miny = min(miny, np.min(righty))\n",
    "\n",
    "        ploty = np.linspace(miny, maxy, img.shape[0])\n",
    "\n",
    "        left_fitx = self.left_coeff[0]*ploty**2 + self.left_coeff[1]*ploty + self.left_coeff[2]  #Y=Ax^2+Bx+C-->[A,B,c]de left\n",
    "        right_fitx = self.right_coeff[0]*ploty**2 + self.right_coeff[1]*ploty + self.right_coeff[2]\n",
    "\n",
    "        # Afficher les borne des voies sur la video\n",
    "        for i, y in enumerate(ploty):\n",
    "            l = int(left_fitx[i])\n",
    "            r = int(right_fitx[i])\n",
    "            y = int(y)\n",
    "            cv2.line(out_img, (l, y), (r, y), (13, 130, 165))\n",
    "\n",
    "        lR, rR, pos = self.position_vehicule()\n",
    "\n",
    "        return out_img\n",
    "\n",
    "    def plot(self, out_img):\n",
    "        np.set_printoptions(precision=6, suppress=True)\n",
    "        lR, rR, pos = self.position_vehicule()\n",
    "        value = None\n",
    "        if abs(self.left_coeff[0]) > abs(self.right_coeff[0]):\n",
    "            value = self.left_coeff[0]\n",
    "        else:\n",
    "            value = self.right_coeff[0]\n",
    "        #les parameters de la route doit etre precise pour determiner exactement la  direction\n",
    "        if abs(value)  <= 0.00015:\n",
    "            self.drirection_val.append('D') #si la pente ~= 0 --->directe lane\n",
    "        elif value < 0:    #si la pente est negatif--->left turn\n",
    "            self.drirection_val.append('L')\n",
    "        else:\n",
    "            self.drirection_val.append('R')    #sinon right_turn    \n",
    "        if len(self.drirection_val) > 10:   #puisque le nombre window est 9 \n",
    "            self.drirection_val.pop(0)      #liberer la matrice de direction pour une nouvelle window\n",
    "        \n",
    "\n",
    "        direction = max(set(self.drirection_val), key = self.drirection_val.count)\n",
    "        #position des symboles de trafic sur video\n",
    "        if direction == 'L':\n",
    "            y, x = self.virage_left[:,:,3].nonzero()\n",
    "            out_img[y, x-100+400+950//2] = self.keep_warn[y, x, :3]\n",
    "            out_img[y, x-100+400//2] = self.virage_left[y, x, :3]\n",
    "        if direction == 'R':\n",
    "            y, x = self.virage_right[:,:,3].nonzero()\n",
    "            out_img[y, x-100+400+950//2] = self.keep_warn[y, x, :3]\n",
    "            out_img[y, x-100+400//2] = self.virage_right[y, x, :3]\n",
    "        if direction == 'D':\n",
    "            y, x = self.ligne_droite[:,:,3].nonzero()\n",
    "            out_img[y, x-100+400+950//2] = self.keep_warn[y, x, :3]\n",
    "            out_img[y, x-100+400//2] = self.ligne_droite[y, x, :3]\n",
    "\n",
    "        return out_img\n",
    "\n",
    "    def position_vehicule(self):\n",
    "        #be carfull to change depending on the application\n",
    "        ym = 2.5/720                     #on suppose que la hauteur ligne hachure ente 1 et 2.5\n",
    "        X_pixel_to_meter = 4/650         #on suppose que la largeur de la route ente 3.5 et 4m\n",
    "\n",
    "        left_fit = self.left_coeff.copy()\n",
    "        right_fit = self.right_coeff.copy()\n",
    "        y_eval = 700 * ym\n",
    "\n",
    "        #R:Le rayon de courbure est calcule de la formule mathematique suivante:\n",
    "        #R = (1 + (dy/dx)^2)^(3/2) / |d^2y/dx^2|\n",
    "        virage_left =  ((1 + (2*left_coeff[0] *y_eval + left_coeff[1])**2)**1.5)  / np.absolute(2*left_coeff[0])\n",
    "        virage_droite = ((1 + (2*right_coeff[0]*y_eval + right_coeff[1])**2)**1.5) / np.absolute(2*right_coeff[0])\n",
    "        xl = np.dot(self.left_coeff, [700**2, 700, 1])    #useage de 700 c'est parce que on a pas utidie la totalite image\n",
    "        xr = np.dot(self.right_coeff, [700**2, 700, 1])   #image size:1280X720---->720 height\n",
    "        camera_center_pos=1280//2\n",
    "        center_entre_lines=(xl+xr)//2\n",
    "        pos = (camera_center_pos - center_entre_lines)*X_pixel_to_meter\n",
    "        return virage_left, virage_droite, pos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b28363fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video project_video_result_1_3.mp4.\n",
      "Moviepy - Writing video project_video_result_1_3.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready project_video_result_1_3.mp4\n"
     ]
    }
   ],
   "source": [
    "#la classe final qui fait appel a toutes les fonctions declare avant en suivant le meme\n",
    "#trajet Calibration-->Thresholding--->ROI---->Change_View--->Detection_Position_lanes--->Apply result to the record\n",
    "class final_class_result:\n",
    "    def __init__(self):\n",
    "        self.calibration = CameraCalibration('camera_cal', 8, 6)          #nx=8,ny=6,folder=camera_cal\n",
    "        self.thresholding = Thresholding()                                #transformer image en binaire(mask)\n",
    "        self.transform = PerspectiveTransformation()                      #changer la vue---->Top_view\n",
    "        self.lanelines = detect_lines()                                      #detection des lignes\n",
    "\n",
    "    def forward(self, img):\n",
    "        out_img = np.copy(img)\n",
    "        img = self.calibration.undistort(img)\n",
    "        img = self.transform.forward(img)\n",
    "        img = self.thresholding.forward(img)\n",
    "        img = self.lanelines.forward(img)\n",
    "        img = self.transform.backward(img)\n",
    "        #cette correspond a la combinaison des pixel des 2 imaegs\n",
    "        out_img = cv2.addWeighted(out_img, 1, img, 0.6, 0)\n",
    "        out_img = self.lanelines.plot(out_img)\n",
    "        return out_img\n",
    "\n",
    "    def video_manip(self, input_path, output_path):\n",
    "        my_vid = VideoFileClip(input_path)\n",
    "        out_vid = my_vid.fl_image(self.forward)\n",
    "        out_vid.write_videofile(output_path, audio=False)        #ignorer tous les sons prises en microphone\n",
    "\n",
    "def main():\n",
    "    inp = 'my2.mp4'                                #chemin video\n",
    "    output = 'project_video_result_1_3.mp4'\n",
    "\n",
    "    final_class_result = final_class_result()\n",
    "    final_class_result.video_manip(inp, output)\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
